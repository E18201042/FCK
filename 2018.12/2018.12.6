1.今天看了王智彬给的论文，这篇论文主要是针对全连接神经网络的推理攻击，深度神经网络复杂，通常有超过数千个参数，使得训练一个攻击模型很困难，
本篇论文通过不同的特征表示来降低攻击模型的复杂性。深度神经网络具有置换不变性，即全连接深度神经网络（FCNNs）在表示使用矩阵时，在节点置换下
是不变的。对FCNNs的每个隐层进行任意排列，并相应地调整权重，可以得到等价的FCNNs。找到FCNNs的置换不变性，就能大大减少分类器（推理模型）的参数个数，
使得训练更容易。
2.在写自然辩证法课程论文。
