成员推理攻击会有效是因为机器学习模型对训练数据和非训练数据的分类有明显的差别，所以可以训练一个攻击模型来判断一个数据记录是否在
目标模型的训练数据集中，按照论文中的实验论述，过拟合会泄漏模型的隐私，比如训练数据，这是因为过拟合说明模型的泛化能力差，易通过
目标模型推理出训练数据的统计信息和分布信息，进而推理出训练数据。，所以防止过拟合可以缓解成员推理攻击。另一种方法是使用尽可能大
的训练数据集和将训练数据集尽可能多的分类，这样会增加推理攻击难度。防止过拟合的方法有droupout、正则化。另外缓解推理攻击可以通过
减少模型输出的预测向量维数（即取前K个高置信度值）、粗化置信度值（四舍五入）和增加输出的不确定性（即熵值）。
