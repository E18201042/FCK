1.上午上了英语讲座，讲的是如何做英文会议报告
2.下午上了机器学习课程，讲的是无监督学习的聚类，主要讲了原型聚类、密度聚类和分层聚类，还讲了关于在社会网络中的社区检测和评估。
3.继续看论文：（图中表示的是每次只对一个类的训练数据进行推理攻击）
图4主要说明了推理攻击有效，查准率(precision)和查全率都高于随机的攻击成功率0.5.还说明了训练数据集越大，攻击准确率越低。
图5主要说明了在类c的置信度越大的情况下，攻击成功率（以查准率和查全率表示）越大。（Purchase Dataset, Amazon, Membership Inference Attack）
还说明了训练迭代次数越多，正则化参数值越大，攻击效果越好，谷歌平台训练的目标模型比亚马逊平台更易受到攻击。
图6(Texas Dataset, Google, Membership Inference Attack )主要展示了在类c的置信度越大的情况下，攻击成功率（以查准率和查全率表示）越大。
图7（Purchase Dataset, Membership Inference Attack ）主要说明了成员推理攻击对于Google、 Amazon (100,1e-4)、 Amazon (10,1e-6)、 Neural Network
上面训练的目标模型攻击成功率，依次递增。
图8报告了针对影子模型的攻击的精确性，阴影模型的训练数据集是真实数据的嘈杂版本(与目标模型的训练数据集分离，但从相同的人群中取样)。随着噪声的增加，精度会下降，
但是攻击的性能仍然优于基线，即使在阴影训练数据中有10%的特征被随机值所取代的情况下，仍然匹配最初的攻击。这表明，即使攻击者对目标模型训练数据分布的假设不是非
常准确，我们的攻击仍然是健壮的。
图9说明训练攻击模型的训练数据的攻击效果由高到低依次为：真实数据>基于模型合成的数据>基于边缘分布（与真实数据具有类似统计分布）的合成数据。
