今天看的论文是:
Membership Inference Attacks Against Machine Learning Models
Pbblished in:2017 IEEE Symposium on Security and Privacy(SP)
Date of Conference:22-26 May 2017
Date Added to IEEE Xplore:26 June 2017
这篇论文讲的是针对机器学习模型的成员推理攻击，讲的是这种攻击会泄露目标模型的隐私，比如训练数据信息。
这篇论文的主要贡献是：
1.设计、实现和评估了针对机器学习模型的第一次成员推理攻击。
2.攻击的方法适用于任意的数据集和模型类别，是通用和定量的，可以用于理解机器学习模型是怎样泄露训练数据集的信息。
3.用户以目标模型应对攻击的表现作为选择标准，选择学习模型和服务。
4.最主要的创新是影子训练技术（生成多个影子模型，模拟目标模型的行为？），训练攻击模型来区分目标模型在成员和非成员上的输出（？）
影子模型训练数据的生成方法：
（1）通过对目标模型的黑盒访问合成数据。
（2）使用目标模型的训练数据集的总体统计数据。
（3）假设对手可以访问目标模型训练数据集的噪声版本。
5.证明了攻击中的阴影模型可以有效使用合成数据和噪声数据。对于目标模型生成的合成数据，成员推理攻击不需事先知道目标模型训练数据的分布情况。
6.研究成果具有实质性的隐私保护意义。

