作者提出的提取模型的对抗策略：
1.隐藏置信度的输出，但是这样还是可以提取模型，只不过复杂点。可以通过以下步骤实现：
(1)首先随机确定访问数据，对目标模型进行访问，并得到预测结果，
(2) 利用这些数据集训练在本地训练机器学习模型
(3) 找到离所训练机器学习模型分类边界很近的数据点，然后将这些数据对目标模型访问
(4)利用输入数据集和访问结果更新重训练模型，重复3 过程直到模型误差低于一定的值。

2.舍入置信度，即减小置信度的精度，这样会降低提取模型的准确性，但是回归树即使舍入置信度也不能抵抗提取攻击。

3.使用查差分隐私，从理论上来说差分隐私可以阻止提取，或者至少减少提取所允许的隐私侵犯的严重程度。降低敌手访问预测查询时学习训练集元素信息的能力。
